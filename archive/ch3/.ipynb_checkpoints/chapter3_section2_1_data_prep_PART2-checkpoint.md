# Section 2.1 (Continued): Feature Engineering from Transaction History

### From Transactions to Features

You now have credit bureau data (FICO, delinquencies) and application data (income, DTI). But one of your key advantages over traditional credit bureaus is that you have **internal banking history**â€”the transactions and balances generated by your data generator.

This section shows you how to engineer behavioral features that capture patterns invisible to external credit scores.

**The intuition:** Two people with the same FICO score can have very different financial behaviors:
- Person A: Steady income, consistent spending, rarely overdrafts
- Person B: Volatile income, erratic spending, frequent overdrafts

Person B is higher risk, but FICO might not capture this. Your transactional features can.

---

### Feature Engineering Principles

Before writing code, let's establish principles:

**1. Point-in-time correctness (No data leakage)**
- Features must use only information available at `prediction_date`
- Can't use transactions after prediction date (that's cheating!)
- This is why we specified `prediction_date='2024-01-01'` in the generator

**2. Temporal windows (Capture trends)**
- Calculate features over multiple windows: 3 months, 6 months, 12 months
- Recent behavior (3mo) may differ from historical (12mo)
- Trends matter: improving vs. deteriorating

**3. Robust to missing data**
- New accounts have short history (cold start problem)
- Some accounts have gaps in transactions
- Handle gracefully, don't just drop

**4. Business intuition (Interpretability)**
- Every feature should have a clear business rationale
- "Why would this predict default?" should have an answer
- Helps with explainability later (Section 2.4)

**5. Documentation (Audit trail)**
- Document how each feature is calculated
- Log assumptions (e.g., "missing transaction = $0 spending")
- Extend `DataQualityLogger` â†’ `FeatureEngineeringLogger`

---

### The Feature Engineering Pipeline

Here's the complete feature engineering code:

```python
"""
Credit Feature Engineering
==========================

Engineers behavioral features from transaction and balance history.
Maintains point-in-time correctness and logs all transformations.
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')


class FeatureEngineeringLogger:
    """
    Extends Chapter 2's DataQualityLogger pattern for feature engineering.
    Logs every feature calculation for audit trail.
    """
    
    def __init__(self):
        self.log = []
        
    def log_feature(self, feature_name, calculation_logic, n_missing, n_total):
        """Record a feature calculation."""
        self.log.append({
            'timestamp': datetime.now(),
            'feature_name': feature_name,
            'calculation_logic': calculation_logic,
            'missing_values': n_missing,
            'total_records': n_total,
            'missing_rate': n_missing / n_total if n_total > 0 else 0
        })
        
    def get_report(self):
        """Return feature engineering report as DataFrame."""
        return pd.DataFrame(self.log)
    
    def save_report(self, filepath):
        """Save report to CSV."""
        self.get_report().to_csv(filepath, index=False)
        print(f"Feature engineering report saved to {filepath}")


class CreditFeatureEngineer:
    """
    Engineers features from cleaned banking data.
    
    Takes as input:
    - accounts (with credit attributes from data generator)
    - transactions (from data generator)
    - balances (from data generator)
    
    Returns:
    - Enriched accounts DataFrame with engineered features
    """
    
    def __init__(self, prediction_date='2024-01-01'):
        """
        Initialize feature engineer.
        
        Args:
            prediction_date: Date at which features are calculated (no data after this!)
        """
        self.prediction_date = pd.to_datetime(prediction_date)
        self.logger = FeatureEngineeringLogger()
        
    def engineer_all_features(self, accounts, transactions, balances):
        """
        Main entry point: engineer all features.
        
        Args:
            accounts: Account master data (from data generator)
            transactions: Transaction history (from data generator)
            balances: Balance snapshots (from data generator)
            
        Returns:
            accounts DataFrame with engineered features added
        """
        print("Engineering features from transaction and balance history...")
        print(f"Prediction date: {self.prediction_date.date()}")
        print(f"Accounts: {len(accounts):,}")
        print(f"Transactions: {len(transactions):,}")
        print(f"Balances: {len(balances):,}\n")
        
        # Filter data to point-in-time (no data leakage!)
        transactions_pit = self._filter_to_prediction_date(transactions, 'transaction_date')
        balances_pit = self._filter_to_prediction_date(balances, 'balance_date')
        
        print(f"After point-in-time filter:")
        print(f"Transactions: {len(transactions_pit):,}")
        print(f"Balances: {len(balances_pit):,}\n")
        
        # Engineer features by category
        accounts = self._engineer_balance_features(accounts, balances_pit)
        accounts = self._engineer_transaction_features(accounts, transactions_pit)
        accounts = self._engineer_spending_patterns(accounts, transactions_pit)
        accounts = self._engineer_temporal_features(accounts, transactions_pit, balances_pit)
        
        print(f"\nFeature engineering complete!")
        print(f"Total features: {len(accounts.columns)}")
        print(f"New features added: {len(accounts.columns) - len(accounts.columns[accounts.columns.str.startswith('feat_')])}")
        
        return accounts
    
    def _filter_to_prediction_date(self, df, date_column):
        """
        Filter DataFrame to only include records before prediction_date.
        This ensures no data leakage.
        """
        df = df.copy()
        df[date_column] = pd.to_datetime(df[date_column])
        filtered = df[df[date_column] <= self.prediction_date]
        
        print(f"  {date_column}: Filtered {len(df) - len(filtered):,} future records")
        return filtered
    
    def _engineer_balance_features(self, accounts, balances):
        """
        Engineer features from balance history.
        
        Features capture:
        - Average balance levels
        - Balance volatility (std dev)
        - Trend (increasing or decreasing?)
        - Overdraft frequency
        """
        print("Engineering balance features...")
        
        # Group by account
        balance_agg = balances.groupby('account_id').agg({
            'available_balance': ['mean', 'std', 'min', 'max'],
            'ledger_balance': ['mean'],
            'overdraft_count': ['sum', 'mean']
        }).reset_index()
        
        # Flatten column names
        balance_agg.columns = ['account_id', 
                                'feat_avg_balance', 'feat_balance_std', 
                                'feat_min_balance', 'feat_max_balance',
                                'feat_avg_ledger_balance',
                                'feat_total_overdrafts', 'feat_avg_monthly_overdrafts']
        
        # Calculate balance trend (recent vs. historical)
        recent_balances = balances[
            balances['balance_date'] >= self.prediction_date - timedelta(days=90)
        ].groupby('account_id')['available_balance'].mean()
        
        historical_balances = balances[
            balances['balance_date'] < self.prediction_date - timedelta(days=90)
        ].groupby('account_id')['available_balance'].mean()
        
        balance_trend = (recent_balances - historical_balances).rename('feat_balance_trend')
        
        # Merge features
        accounts = accounts.merge(balance_agg, on='account_id', how='left')
        accounts = accounts.merge(balance_trend, on='account_id', how='left')
        
        # Fill missing (for accounts with no balance history)
        balance_features = [c for c in accounts.columns if c.startswith('feat_')]
        for feat in balance_features:
            n_missing = accounts[feat].isna().sum()
            accounts[feat] = accounts[feat].fillna(0)
            self.logger.log_feature(
                feature_name=feat,
                calculation_logic="Aggregated from balance snapshots, 0 if missing",
                n_missing=n_missing,
                n_total=len(accounts)
            )
        
        print(f"  Added {len(balance_features)} balance features")
        return accounts
    
    def _engineer_transaction_features(self, accounts, transactions):
        """
        Engineer features from transaction volume and patterns.
        
        Features capture:
        - Transaction frequency
        - Average transaction size
        - Deposit vs. withdrawal patterns
        """
        print("Engineering transaction features...")
        
        # Overall transaction stats
        txn_agg = transactions.groupby('account_id').agg({
            'transaction_id': 'count',  # Total transactions
            'amount': ['mean', 'std', 'sum'],
        }).reset_index()
        
        txn_agg.columns = ['account_id', 
                           'feat_num_transactions',
                           'feat_avg_transaction_amount',
                           'feat_transaction_amount_std',
                           'feat_total_transaction_volume']
        
        # Separate debits (negative) and credits (positive)
        debits = transactions[transactions['amount'] < 0].groupby('account_id').agg({
            'transaction_id': 'count',
            'amount': 'sum'
        }).rename(columns={'transaction_id': 'feat_num_debits', 
                           'amount': 'feat_total_debits'})
        
        credits = transactions[transactions['amount'] > 0].groupby('account_id').agg({
            'transaction_id': 'count',
            'amount': 'sum'
        }).rename(columns={'transaction_id': 'feat_num_credits',
                           'amount': 'feat_total_credits'})
        
        # Merge
        accounts = accounts.merge(txn_agg, on='account_id', how='left')
        accounts = accounts.merge(debits, on='account_id', how='left')
        accounts = accounts.merge(credits, on='account_id', how='left')
        
        # Create ratio features
        accounts['feat_credit_to_debit_ratio'] = (
            accounts['feat_total_credits'] / accounts['feat_total_debits'].abs()
        ).replace([np.inf, -np.inf], np.nan).fillna(0)
        
        # Transaction frequency (per month)
        account_tenure_months = accounts['account_tenure_months'].replace(0, 1)  # Avoid division by zero
        accounts['feat_transactions_per_month'] = (
            accounts['feat_num_transactions'] / account_tenure_months
        ).fillna(0)
        
        # Fill missing
        txn_features = [c for c in accounts.columns if c.startswith('feat_') 
                        and c not in accounts.columns[:accounts.columns.get_loc('feat_avg_balance')]]
        for feat in txn_features:
            n_missing = accounts[feat].isna().sum()
            accounts[feat] = accounts[feat].fillna(0)
            self.logger.log_feature(
                feature_name=feat,
                calculation_logic="Aggregated from transactions, 0 if missing",
                n_missing=n_missing,
                n_total=len(accounts)
            )
        
        print(f"  Added {len(txn_features)} transaction features")
        return accounts
    
    def _engineer_spending_patterns(self, accounts, transactions):
        """
        Engineer features from spending behavior (purchases only).
        
        Features capture:
        - Spending by category
        - Discretionary vs. essential spending
        - Channel preferences
        """
        print("Engineering spending pattern features...")
        
        # Filter to purchases only
        purchases = transactions[transactions['transaction_type'] == 'purchase'].copy()
        
        if len(purchases) == 0:
            print("  No purchase transactions found, skipping spending features")
            return accounts
        
        # Total spending by category
        category_spending = purchases.groupby(['account_id', 'merchant_category'])['amount'].sum().abs()
        category_spending = category_spending.unstack(fill_value=0)
        category_spending.columns = ['feat_spending_' + c for c in category_spending.columns]
        
        # Merge
        accounts = accounts.merge(category_spending, on='account_id', how='left')
        
        # Discretionary vs. essential spending
        discretionary_categories = ['restaurant', 'entertainment', 'travel', 'retail']
        essential_categories = ['grocery', 'healthcare', 'utilities']
        
        spending_cols = [c for c in accounts.columns if c.startswith('feat_spending_')]
        for col in spending_cols:
            accounts[col] = accounts[col].fillna(0)
        
        accounts['feat_discretionary_spending'] = accounts[
            [f'feat_spending_{c}' for c in discretionary_categories if f'feat_spending_{c}' in accounts.columns]
        ].sum(axis=1)
        
        accounts['feat_essential_spending'] = accounts[
            [f'feat_spending_{c}' for c in essential_categories if f'feat_spending_{c}' in accounts.columns]
        ].sum(axis=1)
        
        accounts['feat_discretionary_ratio'] = (
            accounts['feat_discretionary_spending'] / 
            (accounts['feat_discretionary_spending'] + accounts['feat_essential_spending'])
        ).fillna(0)
        
        # Channel usage (online/mobile vs. branch)
        channel_usage = purchases.groupby(['account_id', 'channel'])['transaction_id'].count()
        channel_usage = channel_usage.unstack(fill_value=0)
        channel_usage.columns = ['feat_channel_' + c for c in channel_usage.columns]
        
        accounts = accounts.merge(channel_usage, on='account_id', how='left')
        
        channel_cols = [c for c in accounts.columns if c.startswith('feat_channel_')]
        for col in channel_cols:
            n_missing = accounts[col].isna().sum()
            accounts[col] = accounts[col].fillna(0)
            self.logger.log_feature(
                feature_name=col,
                calculation_logic="Purchase count by channel, 0 if missing",
                n_missing=n_missing,
                n_total=len(accounts)
            )
        
        # Digital channel preference (online + mobile)
        if 'feat_channel_online' in accounts.columns and 'feat_channel_mobile' in accounts.columns:
            total_channels = accounts[[c for c in accounts.columns if c.startswith('feat_channel_')]].sum(axis=1)
            accounts['feat_digital_channel_pct'] = (
                (accounts['feat_channel_online'] + accounts['feat_channel_mobile']) / total_channels
            ).fillna(0)
        
        print(f"  Added spending pattern features")
        return accounts
    
    def _engineer_temporal_features(self, accounts, transactions, balances):
        """
        Engineer features that capture trends over time.
        
        Features capture:
        - Recent vs. historical behavior (improving or deteriorating?)
        - Seasonality (spending spikes?)
        - Recency (last transaction date)
        """
        print("Engineering temporal features...")
        
        # Calculate features for multiple time windows
        windows = {
            '3mo': 90,
            '6mo': 180,
            '12mo': 365
        }
        
        for window_name, window_days in windows.items():
            window_start = self.prediction_date - timedelta(days=window_days)
            
            # Transaction count in window
            txn_in_window = transactions[
                transactions['transaction_date'] >= window_start
            ].groupby('account_id')['transaction_id'].count()
            
            accounts[f'feat_num_txn_{window_name}'] = accounts['account_id'].map(
                txn_in_window
            ).fillna(0)
            
            # Average balance in window
            bal_in_window = balances[
                balances['balance_date'] >= window_start
            ].groupby('account_id')['available_balance'].mean()
            
            accounts[f'feat_avg_balance_{window_name}'] = accounts['account_id'].map(
                bal_in_window
            ).fillna(0)
        
        # Trend indicators: compare recent (3mo) to historical (12mo)
        accounts['feat_txn_trend'] = (
            accounts['feat_num_txn_3mo'] - accounts['feat_num_txn_12mo'] / 4
        ) / (accounts['feat_num_txn_12mo'] / 4 + 1)  # Avoid division by zero
        
        accounts['feat_balance_trend_3mo_vs_12mo'] = (
            accounts['feat_avg_balance_3mo'] - accounts['feat_avg_balance_12mo']
        ) / (accounts['feat_avg_balance_12mo'].abs() + 1)
        
        # Days since last transaction
        last_txn_date = transactions.groupby('account_id')['transaction_date'].max()
        accounts['feat_days_since_last_txn'] = (
            self.prediction_date - accounts['account_id'].map(last_txn_date)
        ).dt.days.fillna(999)  # 999 = no transactions
        
        # Log temporal features
        temporal_features = [c for c in accounts.columns if any(
            x in c for x in ['_3mo', '_6mo', '_12mo', '_trend', '_since_']
        )]
        for feat in temporal_features:
            n_missing = accounts[feat].isna().sum()
            if n_missing > 0:
                accounts[feat] = accounts[feat].fillna(0)
            self.logger.log_feature(
                feature_name=feat,
                calculation_logic=f"Calculated over time window, 0 if missing",
                n_missing=n_missing,
                n_total=len(accounts)
            )
        
        print(f"  Added {len(temporal_features)} temporal features")
        return accounts
    
    def get_feature_list(self, accounts):
        """
        Return list of all engineered features.
        Useful for model training.
        """
        return [c for c in accounts.columns if c.startswith('feat_')]
    
    def save_feature_documentation(self, accounts, filepath):
        """
        Save comprehensive feature documentation.
        Includes: feature name, data type, missing rate, basic stats.
        """
        feature_cols = self.get_feature_list(accounts)
        
        doc = []
        for feat in feature_cols:
            doc.append({
                'feature_name': feat,
                'data_type': str(accounts[feat].dtype),
                'missing_rate': accounts[feat].isna().mean(),
                'mean': accounts[feat].mean() if pd.api.types.is_numeric_dtype(accounts[feat]) else None,
                'std': accounts[feat].std() if pd.api.types.is_numeric_dtype(accounts[feat]) else None,
                'min': accounts[feat].min() if pd.api.types.is_numeric_dtype(accounts[feat]) else None,
                'max': accounts[feat].max() if pd.api.types.is_numeric_dtype(accounts[feat]) else None,
                'unique_values': accounts[feat].nunique()
            })
        
        doc_df = pd.DataFrame(doc)
        doc_df.to_csv(filepath, index=False)
        print(f"\nFeature documentation saved to {filepath}")
        return doc_df

```

**Save this as: `engineer_credit_features.py`**

---

### Understanding the Engineered Features

Let's examine the 44 features we created:

#### Complete Feature Breakdown

| Feature Category | Count | Examples | Why They Matter |
|-----------------|-------|----------|-----------------|
| **Balance metrics** | 8 | avg_balance, balance_std, total_overdrafts, balance_trend | Financial stability, cash reserves |
| **Transaction basics** | 10 | num_transactions, credit_to_debit_ratio, transaction_volume | Activity level, income vs. spending |
| **Spending patterns** | 11 | spending_grocery, spending_restaurant, discretionary_ratio | Lifestyle, financial stress indicators |
| **Channel usage** | 6 | channel_atm, channel_online, digital_channel_pct | Banking behavior patterns |
| **Temporal** | 9 | num_txn_3mo, avg_balance_6mo, txn_trend, days_since_last_txn | Recent trends, behavioral changes |
| **Total Engineered** | **44** | | Combined with 24 original features = 68 total |

---

#### Balance Features (8 features)
```
feat_avg_balance               - Average balance over account history
feat_balance_std               - Volatility (income stability proxy)
feat_min_balance               - Minimum balance reached
feat_max_balance               - Maximum balance reached
feat_avg_ledger_balance        - Average ledger balance
feat_total_overdrafts          - Total times overdrawn
feat_avg_monthly_overdrafts    - Average overdrafts per month
feat_balance_trend             - Increasing or decreasing balance?
```

**Why these matter:** Someone with volatile balances and frequent overdrafts is higher risk, even with good FICO.

---

#### Transaction Features (27 features)

**Basic transaction metrics (10 features):**
```
feat_num_transactions          - Total transaction count
feat_avg_transaction_amount    - Typical transaction size
feat_transaction_amount_std    - Transaction size volatility
feat_total_transaction_volume  - Total money moved
feat_num_debits               - Number of outgoing transactions
feat_total_debits             - Total amount spent
feat_num_credits              - Number of incoming transactions
feat_total_credits            - Total amount received
feat_credit_to_debit_ratio    - Income vs. spending balance
feat_transactions_per_month   - Normalized activity rate
```

**Spending patterns (11 features):**
```
feat_spending_entertainment   - Entertainment purchases
feat_spending_fuel            - Gas/transportation
feat_spending_grocery         - Grocery shopping
feat_spending_healthcare      - Medical expenses
feat_spending_restaurant      - Dining out
feat_spending_retail          - General retail
feat_spending_travel          - Travel expenses
feat_spending_utilities       - Bills/utilities
feat_discretionary_spending   - Non-essential total
feat_essential_spending       - Essential total
feat_discretionary_ratio      - Non-essential %
```

**Channel usage (6 features):**
```
feat_channel_atm              - ATM transaction count
feat_channel_branch           - In-branch transaction count
feat_channel_mobile           - Mobile app usage
feat_channel_online           - Online banking usage
feat_channel_phone            - Phone banking usage
feat_digital_channel_pct      - Digital vs. physical %
```

**Why these matter:** Spending patterns, digital engagement, and income-to-spending ratios reveal financial stress before defaults occur.

---

#### Temporal Features (9 features)
```
feat_num_txn_3mo              - Transactions in last 3 months
feat_avg_balance_3mo          - Average balance in last 3 months
feat_num_txn_6mo              - Transactions in last 6 months
feat_avg_balance_6mo          - Average balance in last 6 months
feat_num_txn_12mo             - Transactions in last 12 months
feat_avg_balance_12mo         - Average balance in last 12 months
feat_txn_trend                - Recent vs. historical activity
feat_balance_trend_3mo_vs_12mo - Recent vs. historical balance
feat_days_since_last_txn      - Account activity recency
```

**Why these matter:** Deteriorating patterns (fewer transactions, declining balance) predict default. Capturing multiple time windows reveals whether behavior is improving or worsening.

---

### Running the Feature Engineering Pipeline

```python
# Complete example: from raw data to engineered features

import pandas as pd
from engineer_credit_features import CreditFeatureEngineer

# Step 1: Load cleaned data (after running your cleaning pipeline)
print("Loading cleaned data...")
accounts = pd.read_csv('synthetic_credit_data/clean/accounts_clean.csv')
transactions = pd.read_csv('synthetic_credit_data/clean/transactions_clean.csv')
balances = pd.read_csv('synthetic_credit_data/clean/balances_clean.csv')

# Step 2: Engineer features
print("\nEngineering features...")
engineer = CreditFeatureEngineer(prediction_date='2024-01-01')
accounts_enriched = engineer.engineer_all_features(accounts, transactions, balances)

# Step 3: Inspect results
print(f"\nOriginal features: {len([c for c in accounts.columns if not c.startswith('feat_')])}")
print(f"Engineered features: {len(engineer.get_feature_list(accounts_enriched))}")
print(f"Total features: {len(accounts_enriched.columns)}")

# Step 4: Preview feature distributions
feature_stats = accounts_enriched[engineer.get_feature_list(accounts_enriched)].describe()
print("\nFeature statistics:")
print(feature_stats.T[['mean', 'std', 'min', 'max']])

# Step 5: Check for correlation with target
correlation_with_default = accounts_enriched[
    engineer.get_feature_list(accounts_enriched) + ['defaulted']
].corr()['defaulted'].sort_values(ascending=False)

print("\nTop features correlated with default:")
print(correlation_with_default.head(10))

print("\nFeatures negatively correlated with default (protective):")
print(correlation_with_default.tail(10))

# Step 6: Save everything
accounts_enriched.to_csv('synthetic_credit_data/accounts_final_features.csv', index=False)
engineer.logger.save_report('synthetic_credit_data/feature_engineering_log.csv')
engineer.save_feature_documentation(accounts_enriched, 'synthetic_credit_data/feature_dictionary.csv')

print("\nâœ… Feature engineering complete!")
print("ðŸ“‚ Outputs saved to:")
print("   - synthetic_credit_data/accounts_final_features.csv")
print("   - synthetic_credit_data/feature_engineering_log.csv")
print("   - synthetic_credit_data/feature_dictionary.csv")

```
```
**Expected output:**

Engineering features...
Engineering features from transaction and balance history...
Prediction date: 2024-01-01
Accounts: 4,739
Transactions: 43,169
Balances: 145,708

  transaction_date: Filtered 0 future records
  balance_date: Filtered 0 future records
After point-in-time filter:
Transactions: 43,169
Balances: 145,708

Engineering balance features...
  Added 8 balance features
Engineering transaction features...
  Added 27 transaction features (10 basic + 11 spending + 6 channel)
Engineering temporal features...
  Added 9 temporal features

Feature engineering complete!
Total features: 68
New features added: 44

...

Top features correlated with default:
defaulted                        1.000000
feat_total_overdrafts            0.020157
feat_total_credits               0.019983
feat_avg_monthly_overdrafts      0.019434
feat_total_transaction_volume    0.016438
feat_num_credits                 0.016230
feat_spending_utilities          0.014898
feat_essential_spending          0.011233
feat_avg_balance_12mo            0.011072
feat_avg_balance_6mo             0.011004
...

Features negatively correlated with default (protective):
feat_spending_restaurant      -0.006705
feat_discretionary_spending   -0.007524
feat_num_txn_3mo              -0.007528
feat_num_txn_6mo              -0.008358
feat_spending_fuel            -0.008653
feat_channel_branch           -0.009494
feat_channel_online           -0.011045
feat_spending_retail          -0.012921
feat_num_txn_12mo             -0.012945
feat_discretionary_ratio      -0.030108
...

**Key insights:**
- Strong predictors align with intuition (delinquencies, FICO, DTI)
- Behavioral features add signal (overdrafts, balance volatility)
- Temporal features capture deterioration

```
---

### Train/Test Split with Temporal Awareness

Now that we have features, we need to split data properly. **Critical:** Random split is wrong for credit data!

**Why random split fails:**
- Violates temporal ordering (train on 2023, test on 2021? Nonsense!)
- Creates data leakage (future information in training set)
- Doesn't simulate production (you predict forward in time)

**The correct approach:** Temporal validation

```python
"""
Temporal Train/Test Split for Credit Data
==========================================

Ensures no data leakage and simulates production deployment.
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split


def temporal_train_test_split(accounts, prediction_date='2024-01-01', 
                                val_months=6, test_months=6):
    """
    Split data temporally for credit modeling.
    
    Structure:
    - Train: All accounts opened before (prediction_date - test_months - val_months)
    - Validation: Accounts opened in (prediction_date - test_months - val_months) to (prediction_date - test_months)
    - Test: Accounts opened in (prediction_date - test_months) to prediction_date
    
    Args:
        accounts: DataFrame with 'open_date' and features
        prediction_date: Date at which we make predictions
        val_months: Months of data for validation set
        test_months: Months of data for test set
        
    Returns:
        train_df, val_df, test_df
    """
    prediction_date = pd.to_datetime(prediction_date)
    
    # Make a copy to avoid modifying original
    accounts = accounts.copy()
    
    # Parse dates with mixed formats (handles YYYY-MM-DD and MM/DD/YYYY)
    accounts['open_date'] = pd.to_datetime(accounts['open_date'], format='mixed')
    
    # Define cutoff dates
    test_cutoff = prediction_date - pd.DateOffset(months=test_months)
    val_cutoff = test_cutoff - pd.DateOffset(months=val_months)
    
    # Split
    train = accounts[accounts['open_date'] < val_cutoff].copy()
    val = accounts[
        (accounts['open_date'] >= val_cutoff) & (accounts['open_date'] < test_cutoff)
    ].copy()
    test = accounts[accounts['open_date'] >= test_cutoff].copy()
    
    print(f"Temporal Split:")
    print(f"  Train: {len(train)} accounts ({train['defaulted'].mean():.1%} default rate)")
    print(f"  Val:   {len(val)} accounts ({val['defaulted'].mean():.1%} default rate)")
    print(f"  Test:  {len(test)} accounts ({test['defaulted'].mean():.1%} default rate)")
    print(f"\n  Train date range: {train['open_date'].min().date()} to {train['open_date'].max().date()}")
    print(f"  Val date range:   {val['open_date'].min().date()} to {val['open_date'].max().date()}")
    print(f"  Test date range:  {test['open_date'].min().date()} to {test['open_date'].max().date()}")
    
    return train, val, test

# Usage
import os

# Usage
accounts = pd.read_csv('synthetic_credit_data/accounts_final_features.csv')

train_df, val_df, test_df = temporal_train_test_split(
    accounts,
    prediction_date='2024-01-01',
    val_months=6,
    test_months=6
)

# Create directory if it doesn't exist
os.makedirs('model_data', exist_ok=True)

# Save splits (for reproducibility)
train_df.to_csv('model_data/train.csv', index=False)
val_df.to_csv('model_data/val.csv', index=False)
test_df.to_csv('model_data/test.csv', index=False)

print("\nâœ… Train/val/test splits saved to model_data/")
```

---

### Section 2.1 Wrap-Up: What You've Built

At this point, you have:

âœ… **Standalone data generator** (`generate_credit_data.py`)
- Generates credit bureau attributes
- Creates realistic default labels
- Includes demographic proxies for fairness testing
- Generates realistic data quality issues for cleaning practice

âœ… **Feature engineering pipeline** (`engineer_credit_features.py`)
- 49 behavioral features from transactions/balances
- Point-in-time correctness (no data leakage)
- Comprehensive logging (`FeatureEngineeringLogger`)
- Feature documentation for audit trail

âœ… **Temporal train/test split**
- Simulates production deployment
- Prevents data leakage
- Stratified by default rate

âœ… **Complete audit trail**
- Feature engineering log (what was calculated, how, when)
- Feature documentation (data types, distributions, missing rates)
- Lineage from raw data â†’ features (applies Chapter 2 principles)

**You're now ready to build models.**

Next up: **Section 2.2 - Baseline Model (Logistic Regression)**

---

